"""
Markdownãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚»ã‚¯ã‚·ãƒ§ãƒ³å˜ä½ã§ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€RAGã‚·ã‚¹ãƒ†ãƒ ã®æ¤œç´¢ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€
Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¦‹å‡ºã—ï¼ˆH2ï¼‰ã”ã¨ã«åˆ†å‰²ã—ã¾ã™ã€‚

æŠ€è¡“é¸å®šç†ç”±:
- æ­£è¦è¡¨ç¾: æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã¿ã§å®Ÿç¾å¯èƒ½ã€è»½é‡ã€ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå®¹æ˜“
- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é§†å‹•è¨­è¨ˆ: ChromaDBã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ã€å¾Œã‹ã‚‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¯èƒ½
- ãƒ­ã‚°é§†å‹•é–‹ç™º: å„å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã‚’ãƒ­ã‚°å‡ºåŠ›ã—ã€å•é¡Œç‰¹å®šã‚’å®¹æ˜“ã«
"""

import os
import re
from typing import List, Dict, Any
import logging

# ãƒ­ã‚°è¨­å®šï¼ˆINFO ãƒ¬ãƒ™ãƒ«ã§æ¨™æº–å‡ºåŠ›ã«å‡ºåŠ›ï¼‰
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def split_into_chunks(content: str, filename: str) -> List[Dict[str, Any]]:
    """
    Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã™ã‚‹

    H1ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ€åˆã®H2ã¾ã§ã‚’ã€Œpreambleï¼ˆåºæ–‡ï¼‰ã€ã¨ã—ã¦æ‰±ã„ã€
    ãã®å¾Œã®å„H2ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å€‹åˆ¥ã®ãƒãƒ£ãƒ³ã‚¯ã¨ã—ã¦åˆ†å‰²ã—ã¾ã™ã€‚

    Args:
        content (str): Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹
        filename (str): ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆä¾‹: "attendance.md"ï¼‰

    Returns:
        List[Dict[str, Any]]: ãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆã€‚å„ãƒãƒ£ãƒ³ã‚¯ã¯ä»¥ä¸‹ã‚’å«ã‚€:
            - id: ãƒãƒ£ãƒ³ã‚¯IDï¼ˆä¾‹: "attendance_0"ï¼‰
            - content: ãƒãƒ£ãƒ³ã‚¯ã®æœ¬æ–‡
            - metadata: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆfilename, section_title, chunk_indexç­‰ï¼‰

    Raises:
        ValueError: contentãŒç©ºã€ã¾ãŸã¯filenameãŒç„¡åŠ¹ãªå ´åˆ

    å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ:
        - H1ï¼ˆ# ã‚¿ã‚¤ãƒˆãƒ«ï¼‰+ åºæ–‡ã‚’æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã¨ã™ã‚‹
        - æ­£è¦è¡¨ç¾ã§H2ï¼ˆ## è¦‹å‡ºã—ï¼‰ã‚’æ¤œå‡ºã—ã¦åˆ†å‰²
        - ç©ºã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯è­¦å‘Šãƒ­ã‚°ã‚’å‡ºåŠ›ã—ã¦ã‚¹ã‚­ãƒƒãƒ—
    """
    # å…¥åŠ›ãƒã‚§ãƒƒã‚¯ï¼ˆåœæ­¢å¯èƒ½æ€§ - ä¸æ­£ãªå…¥åŠ›ã§ç•°å¸¸åœæ­¢ï¼‰
    if not content or not content.strip():
        raise ValueError(f"ç©ºã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã§ã™: {filename}")

    if not filename or not filename.endswith('.md'):
        raise ValueError(f"ç„¡åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«åã§ã™: {filename}")

    logger.info(f"å‡¦ç†é–‹å§‹: {filename}")

    chunks = []
    filename_base = os.path.splitext(filename)[0]  # "attendance.md" â†’ "attendance"

    # æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆMULTILINE modeï¼‰
    # ^ : è¡Œé ­
    # ## : H2è¦‹å‡ºã—ï¼ˆH1ã¯#1ã¤ã€H3ä»¥é™ã¯###ä»¥ä¸Šãªã®ã§é™¤å¤–ï¼‰
    # \s+ : ç©ºç™½æ–‡å­—ï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã‚„ã‚¿ãƒ–ï¼‰ãŒ1æ–‡å­—ä»¥ä¸Š
    # (.+) : è¦‹å‡ºã—ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—1ï¼‰
    # $ : è¡Œæœ«
    h2_pattern = r'^##\s+(.+)$'

    # H2è¦‹å‡ºã—ã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†å‰²
    # re.split ã¯ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ãƒãƒƒãƒã—ãŸéƒ¨åˆ†ã§åˆ†å‰²ã—ã€ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚°ãƒ«ãƒ¼ãƒ—ã‚‚å«ã‚ã¦è¿”ã™
    # çµæœ: [preamble, title1, content1, title2, content2, ...]
    parts = re.split(h2_pattern, content, flags=re.MULTILINE)

    # Preambleï¼ˆH1ã‚¿ã‚¤ãƒˆãƒ« + æœ€åˆã®H2ã¾ã§ã®å†…å®¹ï¼‰ã®å‡¦ç†
    # æ³¨æ„: PreambleãŒçŸ­ã™ãã‚‹ã¨åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®å“è³ªãŒä½ããªã‚Šã€
    # ã‚ã‚‰ã‚†ã‚‹ã‚¯ã‚¨ãƒªã«ä¸­é€”åŠç«¯ã«ãƒãƒƒãƒã—ã¦ã—ã¾ã†å•é¡ŒãŒã‚ã‚‹
    preamble = parts[0].strip()
    has_preamble = bool(preamble)
    short_preamble_to_merge = None  # çŸ­ã„Preambleã¯æœ€åˆã®H2ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«çµåˆ

    # PreambleãŒååˆ†ãªé•·ã•ï¼ˆ50æ–‡å­—ä»¥ä¸Šï¼‰ã®å ´åˆã®ã¿ãƒãƒ£ãƒ³ã‚¯ã¨ã—ã¦ä¿å­˜
    # çŸ­ã„Preambleï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã®ã¿ç­‰ï¼‰ã¯æ¤œç´¢å¯¾è±¡ã‹ã‚‰é™¤å¤–
    MIN_PREAMBLE_LENGTH = 50
    if preamble and len(preamble) >= MIN_PREAMBLE_LENGTH:
        logger.debug(f"Preambleã‚’æ¤œå‡º: {len(preamble)} æ–‡å­—")
        chunks.append({
            "id": f"{filename_base}_0",
            "content": preamble,
            "metadata": {
                "filename": filename,
                "section_title": "(Preamble)",  # åºæ–‡ã‚’è¡¨ã™ç‰¹æ®Šãªåå‰
                "chunk_index": 0,
                "chunk_count": 0,  # å¾Œã§æ›´æ–°
                "char_count": len(preamble),
                "has_preamble": True
            }
        })
    elif preamble:
        # çŸ­ã„Preamble: æœ€åˆã®H2ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«çµåˆã™ã‚‹ãŸã‚ä¿æŒ
        # ã“ã‚Œã«ã‚ˆã‚Šã‚¿ã‚¤ãƒˆãƒ«ãŒã€Œã‚¿ã‚°ã€ã¨ã—ã¦æ©Ÿèƒ½ã—ã€æ¤œç´¢ç²¾åº¦ãŒå‘ä¸Šã™ã‚‹
        short_preamble_to_merge = preamble
        logger.info(f"çŸ­ã„Preambleã‚’æœ€åˆã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«çµåˆäºˆå®š: {filename} ({len(preamble)}æ–‡å­—)")

    # H2ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å‡¦ç†
    # parts[1::2] ã¯ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆå¥‡æ•°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰
    # parts[2::2] ã¯æœ¬æ–‡ï¼ˆå¶æ•°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰
    for i in range(1, len(parts), 2):
        if i + 1 >= len(parts):
            # ã‚¿ã‚¤ãƒˆãƒ«ã ã‘ã§æœ¬æ–‡ãŒãªã„å ´åˆï¼ˆé€šå¸¸ã¯ã‚ã‚Šãˆãªã„ãŒã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å¯¾å¿œï¼‰
            break

        section_title = parts[i].strip()
        section_content = parts[i + 1].strip()

        # æœ€åˆã®H2ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«çŸ­ã„Preambleã‚’çµåˆ
        # ã“ã‚Œã«ã‚ˆã‚Šãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«ï¼ˆä¾‹: "# å‹¤æ€ ç®¡ç†ãƒ«ãƒ¼ãƒ«"ï¼‰ãŒ
        # æœ€åˆã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆä¾‹: "## å‹¤å‹™æ™‚é–“"ï¼‰ã¨ä¸€ç·’ã«æ¤œç´¢å¯¾è±¡ã«ãªã‚‹
        is_first_h2_section = (len(chunks) == 0)
        has_merged_preamble = False
        if is_first_h2_section and short_preamble_to_merge:
            # Preamble + H2è¦‹å‡ºã— + æœ¬æ–‡ ã®å½¢å¼ã§çµåˆ
            section_content = f"{short_preamble_to_merge}\n\n## {section_title}\n{section_content}"
            has_merged_preamble = True
            logger.info(f"Preambleã‚’æœ€åˆã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«çµåˆ: {filename}")

        # ç©ºã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒã‚§ãƒƒã‚¯ï¼ˆå …ç‰¢æ€§ - ç©ºã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        if not section_content:
            # æ”¹å–„å¯èƒ½æ€§: è­¦å‘Šãƒ­ã‚°ã§è¨˜éŒ²ã—ã€å¾Œã§ç©ºã‚»ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’ç¢ºèªå¯èƒ½
            logger.warning(f"ç©ºã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—: {filename} - {section_title}")
            continue

        chunk_idx = len(chunks)  # ç¾åœ¨ã®ãƒãƒ£ãƒ³ã‚¯æ•°ãŒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ãªã‚‹
        logger.debug(f"ãƒãƒ£ãƒ³ã‚¯ä½œæˆ: {section_title} ({len(section_content)} æ–‡å­—)")

        chunks.append({
            "id": f"{filename_base}_{chunk_idx}",
            "content": section_content,
            "metadata": {
                "filename": filename,
                "section_title": section_title,
                "chunk_index": chunk_idx,
                "chunk_count": 0,  # å¾Œã§æ›´æ–°
                "char_count": len(section_content),
                "has_preamble": bool(preamble),  # Preambleã®æœ‰ç„¡
                "has_merged_preamble": has_merged_preamble  # çŸ­ã„PreambleãŒçµåˆã•ã‚ŒãŸã‹
            }
        })

    # ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹: H2è¦‹å‡ºã—ãŒ1ã¤ã‚‚ãªã„å ´åˆï¼ˆå …ç‰¢æ€§ï¼‰
    if not chunks:
        logger.warning(f"H2è¦‹å‡ºã—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå…¨ä½“ã‚’1ãƒãƒ£ãƒ³ã‚¯ã¨ã—ã¦æ‰±ã„ã¾ã™: {filename}")
        chunks.append({
            "id": f"{filename_base}_0",
            "content": content.strip(),
            "metadata": {
                "filename": filename,
                "section_title": "(No Section)",  # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãªã—ã‚’è¡¨ã™
                "chunk_index": 0,
                "chunk_count": 1,
                "char_count": len(content.strip()),
                "has_preamble": False
            }
        })

    # å…¨ãƒãƒ£ãƒ³ã‚¯ã® chunk_count ã‚’æ›´æ–°ï¼ˆå†ç¾æ€§ - å…¨ãƒãƒ£ãƒ³ã‚¯ã«åŒã˜æƒ…å ±ï¼‰
    total_chunks = len(chunks)
    for chunk in chunks:
        chunk["metadata"]["chunk_count"] = total_chunks

    logger.info(f"{filename} â†’ {total_chunks} chunks ã«åˆ†å‰²å®Œäº†")
    return chunks


def load_and_chunk_documents(docs_path: str) -> List[Dict[str, Any]]:
    """
    æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã™ã‚‹

    Args:
        docs_path (str): ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ï¼ˆä¾‹: "data/docs"ï¼‰

    Returns:
        List[Dict[str, Any]]: å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’å«ã‚€ãƒªã‚¹ãƒˆ

    Raises:
        FileNotFoundError: docs_path ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        RuntimeError: .md ãƒ•ã‚¡ã‚¤ãƒ«ãŒ1ã¤ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ

    ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°:
        - ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã¯ãƒ­ã‚°ã‚’è¨˜éŒ²ã—ã¦ç¶™ç¶šï¼ˆå …ç‰¢æ€§ï¼‰
        - å…¨ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å¾Œã«æˆåŠŸã—ãŸãƒãƒ£ãƒ³ã‚¯ã®ã¿ã‚’è¿”å´
    """
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨ãƒã‚§ãƒƒã‚¯ï¼ˆåœæ­¢å¯èƒ½æ€§ï¼‰
    if not os.path.exists(docs_path):
        raise FileNotFoundError(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {docs_path}")

    # Markdownãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
    all_files = os.listdir(docs_path)
    md_files = [f for f in all_files if f.endswith('.md')]

    if not md_files:
        raise RuntimeError(f".md ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {docs_path}")

    logger.info(f"ğŸ“‚ {len(md_files)} å€‹ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º")

    all_chunks = []
    failed_files = []  # å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨˜éŒ²ï¼ˆæ”¹å–„å¯èƒ½æ€§ï¼‰

    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    for filename in md_files:
        filepath = os.path.join(docs_path, filename)

        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆUTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()

            # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
            chunks = split_into_chunks(content, filename)
            all_chunks.extend(chunks)

            # é€²æ—è¡¨ç¤ºï¼ˆæ”¹å–„å¯èƒ½æ€§ - ã©ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã©ã‚Œã ã‘åˆ†å‰²ã•ã‚ŒãŸã‹ï¼‰
            print(f"  ğŸ“„ {filename} â†’ {len(chunks)} ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²")

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã¯ãƒ­ã‚°ã«è¨˜éŒ²ã—ã¦ç¶™ç¶šï¼ˆå …ç‰¢æ€§ï¼‰
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å¤±æ•—: {filename} - {e}")
            failed_files.append(filename)
            continue

    # å‡¦ç†çµæœã®ã‚µãƒãƒªãƒ¼
    logger.info(f"åˆè¨ˆ: {len(all_chunks)} ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ")

    if failed_files:
        # å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯è­¦å‘Šï¼ˆæ”¹å–„å¯èƒ½æ€§ï¼‰
        logger.warning(f"å‡¦ç†å¤±æ•—: {len(failed_files)} ãƒ•ã‚¡ã‚¤ãƒ« - {failed_files}")

    # å†ç¾æ€§ãƒã‚§ãƒƒã‚¯: ãƒãƒ£ãƒ³ã‚¯æ•°ãŒ0ã®å ´åˆã¯ä¾‹å¤–
    if len(all_chunks) == 0:
        raise RuntimeError("ãƒãƒ£ãƒ³ã‚¯ãŒ1ã¤ã‚‚ä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

    return all_chunks


# ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆå˜ä½“å®Ÿè¡Œç”¨ï¼‰
if __name__ == "__main__":
    """
    å˜ä½“ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†

    å®Ÿè¡Œæ–¹æ³•:
        python3 chunker.py

    æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:
        - å„ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒ£ãƒ³ã‚¯æ•°
        - åˆè¨ˆãƒãƒ£ãƒ³ã‚¯æ•°ï¼ˆ13å€‹ï¼‰
        - å„ãƒãƒ£ãƒ³ã‚¯ã®è©³ç´°æƒ…å ±
    """
    print("=" * 60)
    print("Markdownãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ãƒ„ãƒ¼ãƒ« - å˜ä½“ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    print()

    try:
        # data/docs/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†
        chunks = load_and_chunk_documents("data/docs")

        print()
        print("=" * 60)
        print("ãƒãƒ£ãƒ³ã‚¯ä¸€è¦§")
        print("=" * 60)

        # å„ãƒãƒ£ãƒ³ã‚¯ã®è©³ç´°ã‚’è¡¨ç¤º
        for chunk in chunks:
            meta = chunk["metadata"]
            print(f"\nID: {chunk['id']}")
            print(f"  ãƒ•ã‚¡ã‚¤ãƒ«: {meta['filename']}")
            print(f"  ã‚»ã‚¯ã‚·ãƒ§ãƒ³: {meta['section_title']}")
            print(f"  æ–‡å­—æ•°: {meta['char_count']}")
            print(f"  ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {meta['chunk_index']} / {meta['chunk_count']}")
            print(f"  Preambleæœ‰ç„¡: {meta['has_preamble']}")

        print()
        print("=" * 60)
        print(f"âœ… ãƒ†ã‚¹ãƒˆæˆåŠŸ: åˆè¨ˆ {len(chunks)} ãƒãƒ£ãƒ³ã‚¯")
        print("=" * 60)

    except Exception as e:
        print()
        print("=" * 60)
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        print("=" * 60)
        import traceback
        traceback.print_exc()
