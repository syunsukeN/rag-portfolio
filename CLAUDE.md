# CLAUDE.md

このファイルは、Claude Code (claude.ai/code) がこのリポジトリで作業する際のガイダンスを提供します。

## プロジェクト概要

RAG（Retrieval-Augmented Generation）ベースの社内資料検索・質問応答システムです。ベクトルストレージにChromaDB、埋め込みとLLMにGemini、バックエンドAPIにFastAPIを使用しています。

**主要な設計思想:**
- AIの回答は保存されたドキュメントの情報のみに制限
- すべての回答に参照元ドキュメントを明示して透明性を確保
- ナレッジベースに存在しない質問には明示的に回答を拒否

## 重要: 調査・原因分析の基本姿勢（最優先）

### 1) 「事実 / 仮説 / 推測」を必ず分離する
- 事実: ログ・DB・実行結果などで確認できたこと
- 仮説: 事実を説明しうる原因候補（未検証）
- 推測: 検証せずに想像したこと（原則、結論にしない）

### 2) 「根本原因（確定）」は条件を満たしたときのみ使う
以下を **すべて満たした場合のみ** 「確定」と表現してよい:
1. 再現条件が明確（入力・環境・手順が固定）である
2. その原因を除去すると症状が消える（反証実験） または原因がないと症状が出ない（成立実験）
3. 代替説明が主要なものは潰れている（少なくとも上位3つ）

### 3) 仕様が曖昧/矛盾している場合、先に仕様の整合を取る
- README / 実装 / CLAUDE.md の記述が矛盾している場合、調査は誤誘導される。
- まず「現行コードの挙動」を事実として確定し、文書を更新する。

### 4) モデルが原因と言い切る前に必ず行う「最低限チェック」
（モデル特性のせいにしやすい失敗を、構造・設定・データで先に切り分ける）
1. DBに期待チャンクが存在するか（ID / metadata / title）
2. 重複登録・ゴミ残存がないか（件数増加の理由）
3. 埋め込み対象文字列に「見出し/タイトル」が入っているか
4. クエリ拡張/正規化が逆効果になっていないか（一般語混入など）
5. 閾値・n_results・ランキングの僅差問題（誤差で入れ替わる）
6. ベクトル以外（BM25/キーワード一致）で正解が上がるか（切り分け）
7. クエリとドキュメントで task_type / モード設定が適切か（利用しているSDK仕様に沿う）

## 必須コマンド

### 環境構築
```bash
# 仮想環境の作成と有効化
python3 -m venv venv
source venv/bin/activate

# 依存ライブラリのインストール
pip3 install -r requirements.txt

# 環境変数の設定
cp .env.example .env
# .envを編集してCHROMA_GOOGLE_GENAI_API_KEYを設定
```

### データベース操作
```bash
# data/docs/のドキュメントでベクトルデータベースを初期化・更新
python3 setup_db.py
```

### アプリケーション実行
```bash
# ホットリロード付きでFastAPIサーバーを起動
python3 -m uvicorn main:app --reload

# フロントエンドへのアクセス: ブラウザでfrontend/index.htmlを開く
```

## アーキテクチャ

### コアコンポーネント

**バックエンド ([main.py](main.py)):**
- フロントエンド通信のためCORSを有効化したFastAPIサーバー
- `./chroma_db`に永続化するChromaDBクライアント
- 埋め込みとLLM応答の両方にGemini APIを統合
- コレクション名: `company_docs`

**データベースセットアップ ([setup_db.py](setup_db.py)):**
- [data/docs/](data/docs/)からMarkdownドキュメントを読み込み
- ベクトル化にGemini `text-embedding-004`を使用
- メタデータ（ファイル名）と共にChromaDBにベクトルを保存
- 各ドキュメントは「チャンク分割」して保存する可能性がある
  - ※実装（chunker / setup_db）の挙動を最優先の事実とし、README/CLAUDE.mdの記述はそれに合わせること
  - 「単一ベクトル」か「チャンク分割」かを断言する場合は、実際のDB件数・chunk_id生成・保存単位で確認すること

**フロントエンド ([frontend/index.html](frontend/index.html)):**
- スタンドアロンのHTML/CSS/JavaScriptインターフェース
- fetch APIでバックエンドと通信
- ビルドプロセス不要

### データフロー

1. **ドキュメント取り込み:** `setup_db.py` → `.md`ファイル読み込み → Gemini Embedding → ChromaDB
2. **質問処理:** ユーザーの質問 → `/ask`エンドポイント → ChromaDBクエリ（上位2件） → Gemini LLM → 参照元付き回答
3. **検索のみ:** `/search`エンドポイントはLLM処理なしで生のドキュメントチャンクを返却

### APIエンドポイント

- `POST /ask` - メインのRAGエンドポイント（クエリ + LLM応答）
  - リクエスト: `{"text": "質問内容"}`
  - レスポンス: `{"question": str, "answer": str, "sources": [str]}`
- `POST /search` - ベクトル検索のみ（LLMなし）
  - 上位2件のドキュメントを距離スコアと共に返却
- `GET /health` - ヘルスチェック
- `GET /` - ルートエンドポイント

### 主要な設定

**埋め込みモデル:** `models/text-embedding-004` (Gemini)
**LLMモデル:** `models/gemini-2.5-flash-preview-09-2025`
**Temperature:** 0.3（精度重視のため低く設定）
**取得件数:** 上位2件（n_results=2）

### プロンプトエンジニアリング

システムは厳格なシステムプロンプト（[main.py:89-95](main.py#L89-L95)）を使用:
1. 提供されたドキュメントのみに回答を制限
2. 情報が利用できない場合は明示的に表明を要求
3. 参照元の引用を義務化
4. 簡潔で箇条書き形式の回答を強制

## 環境変数

`.env`で必須:
- `CHROMA_GOOGLE_GENAI_API_KEY` - 埋め込みと生成の両方に使用するGoogle AI APIキー

## 重要な注意事項

- ドキュメントはチャンク分割なしで完全なファイルとして保存されるため、大きなドキュメントでは検索品質が制限される可能性があります
- ※上記は「現行実装が本当にチャンク分割なし」の場合のみ正しい。現行実装がチャンク分割しているなら、この文は更新すること。
- ChromaDBは`./chroma_db/`に永続化されます（gitignore対象）
- CORSは現在`allow_origins=["*"]`に設定されています - 本番環境では制限してください
- フロントエンドはデフォルトで`http://localhost:8000`にリクエストを送信します
- [data/docs/](data/docs/)のドキュメントを追加・変更した後は`setup_db.py`を再実行してください

## 開発者向け指示

**ユーザーはAIエンジニアを目指して勉強中のため、以下を必ず守ること:**

1. **実装完了後の解説**: 機能実装が完了したら、初学者向けに以下を説明する
   - なぜその技術・ライブラリを選んだのか
   - コードがどのように動作するのか（処理の流れ）
   - 重要な概念や用語の説明
   - 実務での応用例やベストプラクティス

2. **コメントの追加**: コードには最低限わかりやすい日本語コメントを追加する
   - 各関数・クラスの役割
   - 複雑な処理の流れ
   - なぜその実装にしたのかの理由（必要に応じて）

## 実務品質チェックリスト

機能実装時は以下5点を確認すること:

| 観点 | 確認内容 |
|------|----------|
| 再現性 | 誰が実行しても同じ結果になるか |
| 説明可能性 | なぜその実装にしたか説明できるか |
| 堅牢性 | 更新・例外・運用に耐えるか |
| 停止可能性 | 危険な入力・状況で適切に止まるか |
| 改善可能性 | ログから問題を特定し改善できるか |

## 実装パターンと落とし穴（v2.2.0で学んだ教訓）

### 1. リストのインデックスミスマッチを防ぐ

**問題:** `enumerate`と`continue`を組み合わせると、インデックスがずれる

```python
# ❌ 危険なパターン
for i, m in enumerate(metadatas):
    if some_condition:
        continue  # スキップしてもiは進む
    use_ids[i]  # ← metadatasとidsの対応がずれる可能性

# ✅ 安全なパターン
for doc_id, m in zip(ids, metadatas):
    if some_condition:
        continue  # スキップしても常にペアが維持される
    use_doc_id  # ← 常に正しいペア
```

### 2. 無限ループを構造的に防止する

**問題:** 聞き返し機能で、ボタンクリック後も同じ条件で再度聞き返しが発生

**解決策:** 確定情報が増えるほど、判定の権限を減らす設計

| 確定情報 | 許可される処理 |
|----------|---------------|
| なし | すべての判定OK |
| `filter_file`あり | ドメイン曖昧判定スキップ |
| `chunk_id`あり | **検索自体をスキップ**（判定が走らない） |

**核心:** 検索しない = 曖昧判定が構造的に発生しない

### 3. フォールバック戦略を用意する

**問題:** DB再構築後、古いchunk_idが無効になる

```python
# ✅ フォールバック付き実装
if question.chunk_id:
    result = collection.get(ids=[question.chunk_id])
    if not result["documents"]:
        # chunk_idが見つからない → 通常検索にフォールバック
        logger.warning(f"[CHUNK] Not found, falling back to search")
        # 以下、通常の検索フローへ
    else:
        # 直接回答生成
```

### 4. ChromaDBの返り値形式に注意

```python
# collection.query() の返り値
results["documents"][0]  # List[str]
results["metadatas"][0]  # List[dict]
results["ids"][0]        # List[str]

# collection.get() の返り値（同じ構造だが単一IDでも配列）
result["documents"]  # List[str] ※ [0]なしでもリスト
result["metadatas"]  # List[dict]
```

### 5. グローバル状態のリセットを忘れない

**問題:** フロントエンドでpending変数をリセットし忘れると、次のリクエストに影響

```javascript
// ✅ リクエスト送信後に必ずリセット
const response = await fetch(...);
pendingFilterFile = null;  // 忘れずにリセット
pendingChunkId = null;     // 忘れずにリセット
```

### 6. 調査時は仮説と事実を区別する

**問題:** 仮説段階なのに「根本原因（確定）」と断定してしまった

**悪い例:**
```markdown
## 根本原因（確定）
ChromaDBのチャンク数が異常（27チャンク、期待値は10）
```

↑ 「27が異常」は仮説。新しいドキュメントが追加されていれば正常かもしれない。

**調査の正しい流れ:**

```markdown
## 仮説1
チャンク数が期待値（10）と異なる（実際: 27）

## 事実確認
1. DBに当該チャンク（attendance_1 - 有給休暇）が存在するか？
2. 重複登録が起きていないか？
3. 削除済みファイルのゴミが残っていないか？

## 仮説1の検証結果
- attendance_1は存在する ✅
- 重複なし ✅
- docker_beginner_article.md（17チャンク）が残存 → 削除して再検証

## 再検証後も問題継続 → 仮説2へ
仮説1は部分的に正しかったが、根本原因ではなかった
```

**調査の鉄則:**
1. 仮説段階では「確定」と書かない
2. 「異常」と断定する前に仕様を確認する
3. 仮説は事実で潰してから次へ進む
4. 対策を実行しても解決しない場合は、次の仮説を立てる

### 7. 調査テンプレ（必須フォーマット）
調査・障害報告・改善提案は必ず以下の構造で書く（省略不可）。

```markdown
## 現象
- 何が起きたか（期待 vs 実際）
- 影響範囲（頻度、ユーザー影響）

## 再現手順
- 入力（クエリ/データ/環境）
- 実行コマンド or API呼び出し
- 結果（トップk、スコア）

## 事実（ログ/DB/実行結果）
- DB内に期待データが存在するか
- 件数、重複、ゴミ、メタデータの状態
- 設定値（n_results, threshold, query expansion, task_type等）

## 仮説（優先度順に3つ以上）
1. 仮説A
2. 仮説B
3. 仮説C

## 検証計画（各仮説に対応）
- Aを潰すための具体的手順（反証/成立実験）
- Bを潰すための具体的手順
- Cを潰すための具体的手順

## 検証結果
- A: ✅/❌（証拠）
- B: ✅/❌（証拠）
- C: ✅/❌（証拠）

## 結論（確度を明記）
- 根本原因（確定/高確度/未確定）
- 代替説明が残る場合は残件として列挙

## 対策案（即効/恒久）
- 即効（影響を止める）
- 恒久（再発防止）
- 検証方法（改善の確認方法）
```

### 8. 「モデル原因」判定のための最低限の切り分け実験
モデルが原因と言い切る前に、最低でも以下の2つは実施する:

1) **タイトル強化実験**
- 埋め込み対象の先頭に `タイトル/見出し/カテゴリ` を明示的に追加し、ランキングが改善するか確認

2) **キーワード検索（BM25相当）での比較**
- キーワード一致で正解が上位に来るのに、ベクトルだけ崩れるなら「ベクトル起因」の確度が上がる

（上記2つが未実施の状態で「モデルが原因」と断言しない）

### 9. ログと観測を先に作る（改善可能性のため）
- リクエストごとに以下をログに出す（最小構成）
  - query（正規化後/拡張後）
  - 検索対象フィルタ（filter_file等）
  - top-k ids, titles, scores
  - 「聞き返し判定」の発火理由（閾値/僅差/ドメイン曖昧など）
- 調査で「ログがない」はNG。まずログを追加してから仮説検証する。

## 段階的拡張ロードマップ

このプロジェクトを実務レベルに引き上げるためのフェーズ:

### Phase 1: 制御強化（基本品質）
- [x] 根拠表示（参照ドキュメント名を回答に含める）
- [x] 非回答ルール（資料にない情報は答えない）
- [x] 追加質問フロー（v2.2.0: 聞き返し機能 - 3条件で判定し選択肢を提示）
- [ ] 検索スコア閾値（信頼度の低い検索結果を除外）

### Phase 2: 計測（品質の可視化）
- [ ] 評価用質問セット作成（20-30問、正解の参照文書を紐づけ）
- [ ] Recall@k の計測スクリプト実装
- [ ] 失敗ケースの分類と記録
  - 失敗分類は最低でも以下を含める:
    - データ欠落 / 重複・ゴミ / タイトル未注入 / クエリ拡張暴走 / スコア僅差 / ルーティング不在 / ベクトル限界

### Phase 3: 運用（継続的改善）
- [ ] フィードバックボタン（「この回答は違う」）
- [ ] リクエスト/レスポンスのログ保存
- [ ] 失敗ログからの改善タスク化フロー

### Phase 4: 企業導入レベル
- [ ] アクセス制御（部署・権限による閲覧制限）
- [ ] 禁止質問フィルタ（機密・人事・給与など）
- [ ] 監査ログ（誰が何を聞いたかの記録）

## 機能開発テンプレート

新機能を実装する際は、以下7項目を明確にしてから着手すること:

1. **目的**: この機能の業務上の価値は何か
2. **制約**: 機密情報、速度要件、コスト、禁止事項
3. **入出力**: 入力形式と出力形式（JSON例を含む）
4. **失敗要件**: どんな時に答えないか、エラー時の挙動
5. **テスト観点**: 境界値、例外ケース、回帰テスト
6. **運用**: ログ項目、監視方法、ロールバック手順
7. **変更容易性**: 設定ファイル化、差分更新の容易さ

## 実務成果物チェックリスト

ポートフォリオとして評価されるために、以下のドキュメントを用意すること:

- [ ] **アーキテクチャ図**（システム構成を1枚で説明）
- [ ] **用途定義書**（使っていい用途/ダメな用途を明記）
- [ ] **失敗例集**（想定される失敗パターンと対処法 10個以上）
- [ ] **評価方法**（質問セットと評価指標の定義）
- [ ] **運用手順書**（起動・停止・更新・障害対応の手順）
